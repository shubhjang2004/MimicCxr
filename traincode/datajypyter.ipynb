{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total JPG images found: 105,475\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dataset = r\"MIMICCXR\\mimic-cxr-images\\files\"\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "for big_folder in os.listdir(image_dataset):\n",
    "    big_folder_path = os.path.join(image_dataset, big_folder)\n",
    "    \n",
    "    if not os.path.isdir(big_folder_path):\n",
    "        continue\n",
    "    \n",
    "    for patient_id in os.listdir(big_folder_path):\n",
    "        patient_path = os.path.join(big_folder_path, patient_id)\n",
    "        \n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        \n",
    "        for study_id in os.listdir(patient_path):\n",
    "            study_path = os.path.join(patient_path, study_id)\n",
    "            \n",
    "            if not os.path.isdir(study_path):\n",
    "                continue\n",
    "            \n",
    "            # Count JPG files\n",
    "            for image_file in os.listdir(study_path):\n",
    "                if image_file.lower().endswith('.jpg'):\n",
    "                    total_images += 1\n",
    "\n",
    "print(f\"✅ Total JPG images found: {total_images:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dc7cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DIAGNOSTIC REPORT\n",
      "======================================================================\n",
      "Total images scanned:          105,475\n",
      "Images WITH matching reports:  105,475\n",
      "Images WITHOUT reports:        0\n",
      "Percentage matched:            100.0%\n",
      "\n",
      "======================================================================\n",
      "EXAMPLES OF MISSING REPORTS (first 10):\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dataset = r\"MIMICCXR\\mimic-cxr-images\\files\"\n",
    "report_dataset = r\"MIMICCXR\\mimic-cxr-reports\\files\"\n",
    "\n",
    "total_images = 0\n",
    "images_with_reports = 0\n",
    "images_without_reports = 0\n",
    "missing_report_files = []\n",
    "\n",
    "for big_folder in os.listdir(image_dataset):\n",
    "    big_folder_path = os.path.join(image_dataset, big_folder)\n",
    "    \n",
    "    if not os.path.isdir(big_folder_path):\n",
    "        continue\n",
    "    \n",
    "    for patient_id in os.listdir(big_folder_path):\n",
    "        patient_path = os.path.join(big_folder_path, patient_id)\n",
    "        \n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        \n",
    "        for study_id in os.listdir(patient_path):\n",
    "            study_path = os.path.join(patient_path, study_id)\n",
    "            \n",
    "            if not os.path.isdir(study_path):\n",
    "                continue\n",
    "            \n",
    "            # Check if report exists for this study\n",
    "            report_path = os.path.join(report_dataset, big_folder, patient_id, f\"{study_id}.txt\")\n",
    "            report_exists = os.path.exists(report_path)\n",
    "            \n",
    "            # Count images in this study\n",
    "            study_images = [f for f in os.listdir(study_path) if f.lower().endswith('.jpg')]\n",
    "            num_images = len(study_images)\n",
    "            total_images += num_images\n",
    "            \n",
    "            if report_exists:\n",
    "                images_with_reports += num_images\n",
    "            else:\n",
    "                images_without_reports += num_images\n",
    "                if len(missing_report_files) < 10:  # Store first 10 examples\n",
    "                    missing_report_files.append({\n",
    "                        'big_folder': big_folder,\n",
    "                        'patient_id': patient_id,\n",
    "                        'study_id': study_id,\n",
    "                        'num_images': num_images,\n",
    "                        'expected_report': report_path\n",
    "                    })\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total images scanned:          {total_images:,}\")\n",
    "print(f\"Images WITH matching reports:  {images_with_reports:,}\")\n",
    "print(f\"Images WITHOUT reports:        {images_without_reports:,}\")\n",
    "print(f\"Percentage matched:            {(images_with_reports/total_images)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXAMPLES OF MISSING REPORTS (first 10):\")\n",
    "print(\"=\"*70)\n",
    "for i, missing in enumerate(missing_report_files, 1):\n",
    "    print(f\"\\n{i}. Study: {missing['study_id']}\")\n",
    "    print(f\"   Patient: {missing['patient_id']}\")\n",
    "    print(f\"   Folder: {missing['big_folder']}\")\n",
    "    print(f\"   Images: {missing['num_images']}\")\n",
    "    print(f\"   Expected report at: {missing['expected_report']}\")\n",
    "    print(f\"   Report exists: {os.path.exists(missing['expected_report'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2f3d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total image-report pairs: 105,475\n",
      "✅ Unique images: 105,475\n",
      "✅ Unique reports: 63,751\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dataset = r\"MIMICCXR\\mimic-cxr-images\\files\"\n",
    "report_dataset = r\"MIMICCXR\\mimic-cxr-reports\\files\"\n",
    "\n",
    "images = []\n",
    "reports = []\n",
    "\n",
    "for big_folder in os.listdir(image_dataset):\n",
    "    big_folder_path = os.path.join(image_dataset, big_folder)\n",
    "    \n",
    "    if not os.path.isdir(big_folder_path):\n",
    "        continue\n",
    "    \n",
    "    for patient_id in os.listdir(big_folder_path):\n",
    "        patient_path = os.path.join(big_folder_path, patient_id)\n",
    "        \n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        \n",
    "        for study_id in os.listdir(patient_path):\n",
    "            study_path = os.path.join(patient_path, study_id)\n",
    "            \n",
    "            if not os.path.isdir(study_path):\n",
    "                continue\n",
    "            \n",
    "            report_path = os.path.join(report_dataset, big_folder, patient_id, f\"{study_id}.txt\")\n",
    "            \n",
    "            # Only process .jpg files\n",
    "            for image_file in os.listdir(study_path):\n",
    "                if image_file.lower().endswith('.jpg'):  # ← FIX: Only JPG files!\n",
    "                    image_path = os.path.join(study_path, image_file)\n",
    "                    images.append(image_path)\n",
    "                    reports.append(report_path)\n",
    "\n",
    "print(f\"✅ Total image-report pairs: {len(images):,}\")\n",
    "print(f\"✅ Unique images: {len(set(images)):,}\")\n",
    "print(f\"✅ Unique reports: {len(set(reports)):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfa7e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading report texts...\n",
      "\n",
      "======================================================================\n",
      "FINAL DATASET\n",
      "======================================================================\n",
      "Total samples:       105,475\n",
      "Unique images:       105,475\n",
      "Unique reports:      63,751\n",
      "\n",
      "Report statistics:\n",
      "  Mean words:        85.8\n",
      "  Median words:      77\n",
      "  Min words:         15\n",
      "  Max words:         552\n",
      "\n",
      "Images per study:\n",
      "  Mean:              1.65\n",
      "  Distribution:\n",
      "    1 image(s):  28,787 studies\n",
      "    2 image(s):  28,870 studies\n",
      "    3 image(s):  5,468 studies\n",
      "    4 image(s):  594 studies\n",
      "    5 image(s):  24 studies\n",
      "\n",
      "✅ Saved to: mimic_complete_dataset.csv\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'image_path': images,\n",
    "    'report_path': reports\n",
    "})\n",
    "\n",
    "# Read report texts\n",
    "print(\"Reading report texts...\")\n",
    "def read_report(path):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read().strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df['report_text'] = df['report_path'].apply(read_report)\n",
    "\n",
    "# Remove empty reports\n",
    "df = df[df['report_text'] != \"\"]\n",
    "\n",
    "# Add metadata\n",
    "df['report_words'] = df['report_text'].str.split().str.len()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL DATASET\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total samples:       {len(df):,}\")\n",
    "print(f\"Unique images:       {df['image_path'].nunique():,}\")\n",
    "print(f\"Unique reports:      {df['report_path'].nunique():,}\")\n",
    "print(f\"\\nReport statistics:\")\n",
    "print(f\"  Mean words:        {df['report_words'].mean():.1f}\")\n",
    "print(f\"  Median words:      {df['report_words'].median():.0f}\")\n",
    "print(f\"  Min words:         {df['report_words'].min()}\")\n",
    "print(f\"  Max words:         {df['report_words'].max()}\")\n",
    "\n",
    "# Images per study distribution\n",
    "images_per_study = df.groupby('report_path').size()\n",
    "print(f\"\\nImages per study:\")\n",
    "print(f\"  Mean:              {images_per_study.mean():.2f}\")\n",
    "print(f\"  Distribution:\")\n",
    "for n in sorted(images_per_study.value_counts().index[:5]):\n",
    "    count = images_per_study.value_counts()[n]\n",
    "    print(f\"    {n} image(s):  {count:,} studies\")\n",
    "\n",
    "# Save\n",
    "df.to_csv('mimic_complete_dataset.csv', index=False)\n",
    "print(f\"\\n✅ Saved to: mimic_complete_dataset.csv\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e726c2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATASET SPLITTING - BY STUDY\n",
      "======================================================================\n",
      "Total images:    105,475\n",
      "Unique studies:  63,751\n",
      "\n",
      "Train studies: 57,375 (90.0%)\n",
      "Val studies:   6,376 (10.0%)\n",
      "\n",
      "======================================================================\n",
      "FINAL SPLIT\n",
      "======================================================================\n",
      "Train: 94,949 images from 57,375 studies\n",
      "Val:   10,526 images from 6,376 studies\n",
      "\n",
      "✅ No overlap - split is valid!\n",
      "\n",
      "✅ Saved train.csv (94,949 samples)\n",
      "✅ Saved val.csv (10,526 samples)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD DATASET\n",
    "# ==============================================================================\n",
    "\n",
    "df = pd.read_csv('mimic_complete_dataset.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATASET SPLITTING - BY STUDY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total images:    {len(df):,}\")\n",
    "print(f\"Unique studies:  {df['report_path'].nunique():,}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SPLIT BY STUDY (90% train, 10% val)\n",
    "# ==============================================================================\n",
    "\n",
    "# Get unique studies (reports)\n",
    "unique_studies = df['report_path'].unique()  # 63,751 studies\n",
    "\n",
    "# Split: 90% train, 10% val\n",
    "train_studies, val_studies = train_test_split(\n",
    "    unique_studies,\n",
    "    test_size=0.1,      # 10% for validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain studies: {len(train_studies):,} ({len(train_studies)/len(unique_studies)*100:.1f}%)\")\n",
    "print(f\"Val studies:   {len(val_studies):,} ({len(val_studies)/len(unique_studies)*100:.1f}%)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# GET ALL IMAGES FOR EACH SPLIT\n",
    "# ==============================================================================\n",
    "\n",
    "# Get all images that belong to train studies\n",
    "train_df = df[df['report_path'].isin(train_studies)]\n",
    "\n",
    "# Get all images that belong to val studies\n",
    "val_df = df[df['report_path'].isin(val_studies)]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL SPLIT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train: {len(train_df):,} images from {len(train_studies):,} studies\")\n",
    "print(f\"Val:   {len(val_df):,} images from {len(val_studies):,} studies\")\n",
    "\n",
    "# Verify no overlap\n",
    "overlap = set(train_studies) & set(val_studies)\n",
    "assert len(overlap) == 0, \"ERROR: Overlap detected!\"\n",
    "print(f\"\\n✅ No overlap - split is valid!\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SAVE SPLITS\n",
    "# ==============================================================================\n",
    "\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved train.csv ({len(train_df):,} samples)\")\n",
    "print(f\"✅ Saved val.csv ({len(val_df):,} samples)\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
